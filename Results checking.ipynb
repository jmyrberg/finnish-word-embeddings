{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/finnish.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0 lines\n",
      "Read 100 lines\n",
      "Read 200 lines\n",
      "Read 300 lines\n",
      "Read 400 lines\n",
      "Read 500 lines\n",
      "Read 600 lines\n",
      "Read 700 lines\n",
      "Read 800 lines\n",
      "Read 900 lines\n",
      "Read 1000 lines\n",
      "Read 1100 lines\n",
      "Read 1200 lines\n",
      "Read 1300 lines\n",
      "Read 1400 lines\n",
      "Read 1500 lines\n",
      "Read 1600 lines\n",
      "Read 1700 lines\n",
      "Read 1800 lines\n",
      "Read 1900 lines\n",
      "Read 2000 lines\n",
      "Read 2100 lines\n",
      "Read 2200 lines\n",
      "Read 2300 lines\n",
      "Read 2400 lines\n",
      "Read 2500 lines\n",
      "Read 2600 lines\n",
      "Read 2700 lines\n",
      "Read 2800 lines\n",
      "Read 2900 lines\n",
      "Read 3000 lines\n",
      "Read 3100 lines\n",
      "Read 3200 lines\n",
      "Read 3300 lines\n",
      "Read 3400 lines\n",
      "Read 3500 lines\n",
      "Read 3600 lines\n",
      "Read 3700 lines\n",
      "Read 3800 lines\n",
      "Read 3900 lines\n",
      "Read 4000 lines\n",
      "Read 4100 lines\n",
      "Read 4200 lines\n",
      "Read 4300 lines\n",
      "Read 4400 lines\n",
      "Read 4500 lines\n",
      "Read 4600 lines\n",
      "Read 4700 lines\n",
      "Read 4800 lines\n",
      "Read 4900 lines\n",
      "Read 5000 lines\n",
      "Read 5100 lines\n",
      "Read 5200 lines\n",
      "Read 5300 lines\n",
      "Read 5400 lines\n",
      "Read 5500 lines\n",
      "Read 5600 lines\n",
      "Read 5700 lines\n",
      "Read 5800 lines\n",
      "Read 5900 lines\n",
      "Read 6000 lines\n",
      "Read 6100 lines\n",
      "Read 6200 lines\n",
      "Read 6300 lines\n",
      "Read 6400 lines\n",
      "Read 6500 lines\n",
      "Read 6600 lines\n",
      "Read 6700 lines\n",
      "Read 6800 lines\n",
      "Read 6900 lines\n",
      "Read 7000 lines\n",
      "Read 7100 lines\n",
      "Read 7200 lines\n",
      "Read 7300 lines\n",
      "Read 7400 lines\n",
      "Read 7500 lines\n",
      "Read 7600 lines\n",
      "Read 7700 lines\n",
      "Read 7800 lines\n",
      "Read 7900 lines\n",
      "Read 8000 lines\n",
      "Read 8100 lines\n",
      "Read 8200 lines\n",
      "Read 8300 lines\n",
      "Read 8400 lines\n",
      "Read 8500 lines\n",
      "Read 8600 lines\n",
      "Read 8700 lines\n",
      "Read 8800 lines\n",
      "Read 8900 lines\n",
      "Read 9000 lines\n",
      "Read 9100 lines\n",
      "Read 9200 lines\n",
      "Read 9300 lines\n",
      "Read 9400 lines\n",
      "Read 9500 lines\n",
      "Read 9600 lines\n",
      "Read 9700 lines\n",
      "Read 9800 lines\n",
      "Read 9900 lines\n",
      "Read 10000 lines\n",
      "Read 10100 lines\n",
      "Read 10200 lines\n",
      "Read 10300 lines\n",
      "Read 10400 lines\n",
      "Read 10500 lines\n",
      "Read 10600 lines\n",
      "Read 10700 lines\n",
      "Read 10800 lines\n",
      "Read 10900 lines\n",
      "Read 11000 lines\n",
      "Read 11100 lines\n",
      "Read 11200 lines\n",
      "Read 11300 lines\n",
      "Read 11400 lines\n",
      "Read 11500 lines\n",
      "Read 11600 lines\n",
      "Read 11700 lines\n",
      "Read 11800 lines\n",
      "Read 11900 lines\n",
      "Read 12000 lines\n",
      "Read 12100 lines\n",
      "Read 12200 lines\n",
      "Read 12300 lines\n",
      "Read 12400 lines\n",
      "Read 12500 lines\n",
      "Read 12600 lines\n",
      "Read 12700 lines\n",
      "Read 12800 lines\n",
      "Read 12900 lines\n",
      "Read 13000 lines\n",
      "Read 13100 lines\n",
      "Read 13200 lines\n",
      "Read 13300 lines\n",
      "Read 13400 lines\n",
      "Read 13500 lines\n",
      "Read 13600 lines\n",
      "Read 13700 lines\n",
      "Read 13800 lines\n",
      "Read 13900 lines\n",
      "Read 14000 lines\n",
      "Read 14100 lines\n",
      "Read 14200 lines\n",
      "Read 14300 lines\n",
      "Read 14400 lines\n",
      "Read 14500 lines\n",
      "Read 14600 lines\n",
      "Read 14700 lines\n",
      "Read 14800 lines\n",
      "Read 14900 lines\n",
      "Read 15000 lines\n",
      "Read 15100 lines\n",
      "Read 15200 lines\n",
      "Read 15300 lines\n",
      "Read 15400 lines\n",
      "Read 15500 lines\n",
      "Read 15600 lines\n",
      "Read 15700 lines\n",
      "Read 15800 lines\n",
      "Read 15900 lines\n",
      "Read 16000 lines\n",
      "Read 16100 lines\n",
      "Read 16200 lines\n",
      "Read 16300 lines\n",
      "Read 16400 lines\n",
      "Read 16500 lines\n",
      "Read 16600 lines\n",
      "Read 16700 lines\n",
      "Read 16800 lines\n",
      "Read 16900 lines\n",
      "Read 17000 lines\n",
      "Read 17100 lines\n",
      "Read 17200 lines\n",
      "Read 17300 lines\n",
      "Read 17400 lines\n",
      "Read 17500 lines\n",
      "Read 17600 lines\n",
      "Read 17700 lines\n",
      "Read 17800 lines\n",
      "Read 17900 lines\n",
      "Read 18000 lines\n",
      "Read 18100 lines\n",
      "Read 18200 lines\n",
      "Read 18300 lines\n",
      "Read 18400 lines\n",
      "Read 18500 lines\n",
      "Read 18600 lines\n",
      "Read 18700 lines\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-441db5cdfb19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m sw = SentenceWriter('./data/feed/iltalehti.jl', \n\u001b[0;32m---> 58\u001b[0;31m                     './data/preprocessed/test.csv').preprocess()\n\u001b[0m",
      "\u001b[0;32m<ipython-input-231-441db5cdfb19>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0msents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline_to_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mfout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-231-441db5cdfb19>\u001b[0m in \u001b[0;36mline_to_sents\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0msents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0msent_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, texts, as_tuples, n_threads, batch_size, disable, cleanup)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0moriginal_strings_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mnr_seen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m_pipe\u001b[0;34m(func, docs)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    555\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer._attach_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.get\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\spacy\\lang\\lex_attrs.py\u001b[0m in \u001b[0;36mis_alpha\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m \u001b[1;32mdef\u001b[0m \u001b[0mis_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_digit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_lower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from spacy.lang.fi import Finnish\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.tokens import Doc,Span,Token\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "nlp = Finnish()\n",
    "sentencizer = nlp.create_pipe('sentencizer')\n",
    "nlp.add_pipe(sentencizer)\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "def clean_token(token): \n",
    "    if len(re.sub(r'[^\\w\\s]', '', token.text).strip()) == 0:\n",
    "        return ''\n",
    "    token = token.text\n",
    "    if token[-1] in string.punctuation:\n",
    "        token = token[:-1]\n",
    "    token = re.sub(r'[\\\"\\â€\\'\\`\\(\\)\\[\\]]', '', token)\n",
    "    return token.strip()\n",
    "\n",
    "Token.set_extension('processed', getter=clean_token, force=True)\n",
    "\n",
    "class SentenceWriter(object):\n",
    "    \n",
    "    def __init__(self, input_filepath, output_filepath,\n",
    "                 min_sentence_tokens=5):\n",
    "        self.input_filepath = input_filepath\n",
    "        self.output_filepath = output_filepath\n",
    "        self.min_sentence_tokens = min_sentence_tokens\n",
    "        \n",
    "    def line_to_sents(self, line):\n",
    "        line = json.loads(line)['content']\n",
    "        sents = []\n",
    "        for doc in nlp.pipe(line):\n",
    "            for sent in tokenizer.pipe(s.string.strip() for s in doc.sents):\n",
    "                sent_tokens = []\n",
    "                for token in sent:\n",
    "                    if len(token) > 0:\n",
    "                        sent_tokens.append(token._.processed)\n",
    "                \n",
    "                if len(sent_tokens) > self.min_sentence_tokens:\n",
    "                    sents.append(' '.join(sent_tokens))\n",
    "        return sents\n",
    "        \n",
    "    def preprocess(self):\n",
    "        with open(self.input_filepath, 'r', encoding='utf8') as fin:\n",
    "            with open(self.output_filepath, 'a', encoding='utf8') as fout:\n",
    "                for i,line in enumerate(fin):\n",
    "                    sents = self.line_to_sents(line)\n",
    "                    if len(sents) > 0:\n",
    "                        fout.write('\\n'.join(sents))\n",
    "                        \n",
    "                    if i % 100 == 0:\n",
    "                        print('Read %s lines' % i)\n",
    "                        \n",
    "sw = SentenceWriter('./data/feed/iltalehti.jl', \n",
    "                    './data/preprocessed/test.csv').preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sents = Parallel(n_jobs=4)(delayed(process_content)(l)\n",
    "#                           for l in tqdm_notebook(df['content'].values[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = LineSentence('./data/preprocessed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(\n",
    "    min_count=10,\n",
    "    window=4,\n",
    "    size=100,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-24 22:57:54,609 : INFO : collecting all words and their counts\n",
      "2019-06-24 22:57:54,609 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-06-24 22:58:02,621 : INFO : PROGRESS: at sentence #1000000, processed 12513689 words, keeping 193927 word types\n",
      "2019-06-24 22:58:10,112 : INFO : collected 434928 word types from a corpus of 24232875 raw words and 1974149 sentences\n",
      "2019-06-24 22:58:10,112 : INFO : Loading a fresh vocabulary\n",
      "2019-06-24 22:58:10,954 : INFO : min_count=10 retains 79968 unique words (18% of original 434928, drops 354960)\n",
      "2019-06-24 22:58:10,970 : INFO : min_count=10 leaves 23543299 word corpus (97% of original 24232875, drops 689576)\n",
      "2019-06-24 22:58:11,204 : INFO : deleting the raw counts dictionary of 434928 items\n",
      "2019-06-24 22:58:11,235 : INFO : sample=0.001 downsamples 19 most-common words\n",
      "2019-06-24 22:58:11,235 : INFO : downsampling leaves estimated 21807383 word corpus (92.6% of prior 23543299)\n",
      "2019-06-24 22:58:11,578 : INFO : estimated required memory for 79968 words and 100 dimensions: 103958400 bytes\n",
      "2019-06-24 22:58:11,578 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v.build_vocab(sents, progress_per=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-24 22:58:12,546 : INFO : training model with 4 workers on 79968 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2019-06-24 22:58:13,560 : INFO : EPOCH 1 - PROGRESS: at 2.84% examples, 549253 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:14,964 : INFO : EPOCH 1 - PROGRESS: at 5.22% examples, 419355 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-24 22:58:15,968 : INFO : EPOCH 1 - PROGRESS: at 8.28% examples, 466199 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:16,981 : INFO : EPOCH 1 - PROGRESS: at 10.72% examples, 488887 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:17,995 : INFO : EPOCH 1 - PROGRESS: at 12.94% examples, 496742 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:18,996 : INFO : EPOCH 1 - PROGRESS: at 15.08% examples, 499211 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:20,010 : INFO : EPOCH 1 - PROGRESS: at 17.41% examples, 505189 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:21,024 : INFO : EPOCH 1 - PROGRESS: at 19.79% examples, 510646 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:22,023 : INFO : EPOCH 1 - PROGRESS: at 22.13% examples, 513833 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:23,042 : INFO : EPOCH 1 - PROGRESS: at 24.50% examples, 517007 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:24,277 : INFO : EPOCH 1 - PROGRESS: at 26.29% examples, 496135 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-24 22:58:25,292 : INFO : EPOCH 1 - PROGRESS: at 28.69% examples, 497223 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:26,308 : INFO : EPOCH 1 - PROGRESS: at 30.73% examples, 495767 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:27,324 : INFO : EPOCH 1 - PROGRESS: at 32.98% examples, 497052 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:28,343 : INFO : EPOCH 1 - PROGRESS: at 35.42% examples, 499941 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:29,357 : INFO : EPOCH 1 - PROGRESS: at 37.87% examples, 503388 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:30,368 : INFO : EPOCH 1 - PROGRESS: at 40.26% examples, 505570 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:31,385 : INFO : EPOCH 1 - PROGRESS: at 42.65% examples, 507481 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:32,399 : INFO : EPOCH 1 - PROGRESS: at 45.13% examples, 509763 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:33,538 : INFO : EPOCH 1 - PROGRESS: at 46.76% examples, 499750 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:34,552 : INFO : EPOCH 1 - PROGRESS: at 49.27% examples, 502732 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:35,550 : INFO : EPOCH 1 - PROGRESS: at 51.77% examples, 505435 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 22:58:36,548 : INFO : EPOCH 1 - PROGRESS: at 54.19% examples, 507175 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:37,568 : INFO : EPOCH 1 - PROGRESS: at 56.61% examples, 508566 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:38,575 : INFO : EPOCH 1 - PROGRESS: at 58.73% examples, 507184 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:39,591 : INFO : EPOCH 1 - PROGRESS: at 61.18% examples, 508727 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:40,605 : INFO : EPOCH 1 - PROGRESS: at 63.61% examples, 509972 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:41,606 : INFO : EPOCH 1 - PROGRESS: at 64.78% examples, 501477 words/s, in_qsize 2, out_qsize 0\n",
      "2019-06-24 22:58:42,628 : INFO : EPOCH 1 - PROGRESS: at 67.46% examples, 504500 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:43,627 : INFO : EPOCH 1 - PROGRESS: at 69.77% examples, 506393 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:44,646 : INFO : EPOCH 1 - PROGRESS: at 72.43% examples, 507252 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:45,644 : INFO : EPOCH 1 - PROGRESS: at 75.38% examples, 508915 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:46,643 : INFO : EPOCH 1 - PROGRESS: at 78.19% examples, 510269 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:47,679 : INFO : EPOCH 1 - PROGRESS: at 81.13% examples, 511156 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:48,677 : INFO : EPOCH 1 - PROGRESS: at 82.48% examples, 504422 words/s, in_qsize 0, out_qsize 2\n",
      "2019-06-24 22:58:49,683 : INFO : EPOCH 1 - PROGRESS: at 85.56% examples, 507403 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:50,712 : INFO : EPOCH 1 - PROGRESS: at 88.48% examples, 509179 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:51,726 : INFO : EPOCH 1 - PROGRESS: at 91.39% examples, 510692 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:52,748 : INFO : EPOCH 1 - PROGRESS: at 94.29% examples, 512029 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:53,762 : INFO : EPOCH 1 - PROGRESS: at 96.89% examples, 512349 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:54,761 : INFO : EPOCH 1 - PROGRESS: at 98.10% examples, 506570 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:55,502 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-24 22:58:55,502 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-24 22:58:55,502 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-24 22:58:55,518 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-24 22:58:55,533 : INFO : EPOCH - 1 : training on 24232875 raw words (21807296 effective words) took 43.0s, 507504 effective words/s\n",
      "2019-06-24 22:58:56,534 : INFO : EPOCH 2 - PROGRESS: at 2.71% examples, 529711 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:57,532 : INFO : EPOCH 2 - PROGRESS: at 5.58% examples, 539955 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:58,549 : INFO : EPOCH 2 - PROGRESS: at 8.46% examples, 541333 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:58:59,549 : INFO : EPOCH 2 - PROGRESS: at 10.76% examples, 540716 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:00,575 : INFO : EPOCH 2 - PROGRESS: at 13.05% examples, 540601 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:01,597 : INFO : EPOCH 2 - PROGRESS: at 15.43% examples, 543816 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:02,612 : INFO : EPOCH 2 - PROGRESS: at 17.76% examples, 543588 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:03,623 : INFO : EPOCH 2 - PROGRESS: at 18.97% examples, 511013 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:04,637 : INFO : EPOCH 2 - PROGRESS: at 21.49% examples, 518736 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:05,651 : INFO : EPOCH 2 - PROGRESS: at 23.88% examples, 521056 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:06,656 : INFO : EPOCH 2 - PROGRESS: at 26.33% examples, 523699 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:07,656 : INFO : EPOCH 2 - PROGRESS: at 28.83% examples, 524088 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:08,670 : INFO : EPOCH 2 - PROGRESS: at 31.19% examples, 527241 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:09,670 : INFO : EPOCH 2 - PROGRESS: at 33.55% examples, 528296 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:10,685 : INFO : EPOCH 2 - PROGRESS: at 35.94% examples, 529065 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:11,699 : INFO : EPOCH 2 - PROGRESS: at 38.36% examples, 529951 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:12,722 : INFO : EPOCH 2 - PROGRESS: at 39.55% examples, 514664 words/s, in_qsize 2, out_qsize 0\n",
      "2019-06-24 22:59:13,722 : INFO : EPOCH 2 - PROGRESS: at 42.08% examples, 518453 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 22:59:14,755 : INFO : EPOCH 2 - PROGRESS: at 44.44% examples, 518467 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:15,754 : INFO : EPOCH 2 - PROGRESS: at 46.72% examples, 518121 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:16,764 : INFO : EPOCH 2 - PROGRESS: at 49.19% examples, 519808 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:17,779 : INFO : EPOCH 2 - PROGRESS: at 51.60% examples, 520724 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:18,796 : INFO : EPOCH 2 - PROGRESS: at 54.11% examples, 522374 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:20,046 : INFO : EPOCH 2 - PROGRESS: at 55.97% examples, 512449 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-24 22:59:21,062 : INFO : EPOCH 2 - PROGRESS: at 58.53% examples, 514981 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:22,081 : INFO : EPOCH 2 - PROGRESS: at 60.94% examples, 515978 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-24 22:59:23,087 : INFO : EPOCH 2 - PROGRESS: at 63.36% examples, 517104 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:24,085 : INFO : EPOCH 2 - PROGRESS: at 65.85% examples, 518481 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:25,109 : INFO : EPOCH 2 - PROGRESS: at 68.24% examples, 519593 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:26,118 : INFO : EPOCH 2 - PROGRESS: at 70.57% examples, 520290 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:27,117 : INFO : EPOCH 2 - PROGRESS: at 73.37% examples, 521091 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:28,352 : INFO : EPOCH 2 - PROGRESS: at 75.54% examples, 514273 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:29,345 : INFO : EPOCH 2 - PROGRESS: at 78.49% examples, 516194 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:30,363 : INFO : EPOCH 2 - PROGRESS: at 81.52% examples, 517684 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 22:59:31,361 : INFO : EPOCH 2 - PROGRESS: at 84.42% examples, 519443 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:32,362 : INFO : EPOCH 2 - PROGRESS: at 87.30% examples, 521102 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 22:59:33,751 : INFO : EPOCH 2 - PROGRESS: at 89.66% examples, 514381 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-24 22:59:34,764 : INFO : EPOCH 2 - PROGRESS: at 92.84% examples, 517405 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:35,762 : INFO : EPOCH 2 - PROGRESS: at 95.73% examples, 518740 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:36,777 : INFO : EPOCH 2 - PROGRESS: at 98.23% examples, 519069 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:37,483 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-24 22:59:37,483 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-24 22:59:37,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-24 22:59:37,499 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-24 22:59:37,514 : INFO : EPOCH - 2 : training on 24232875 raw words (21807712 effective words) took 42.0s, 519535 effective words/s\n",
      "2019-06-24 22:59:38,515 : INFO : EPOCH 3 - PROGRESS: at 2.84% examples, 552619 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:39,530 : INFO : EPOCH 3 - PROGRESS: at 5.84% examples, 564226 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 22:59:40,522 : INFO : EPOCH 3 - PROGRESS: at 7.48% examples, 480266 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:41,522 : INFO : EPOCH 3 - PROGRESS: at 10.11% examples, 502007 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:42,548 : INFO : EPOCH 3 - PROGRESS: at 12.43% examples, 511446 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:43,563 : INFO : EPOCH 3 - PROGRESS: at 14.79% examples, 519588 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:44,570 : INFO : EPOCH 3 - PROGRESS: at 17.17% examples, 526221 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:45,568 : INFO : EPOCH 3 - PROGRESS: at 19.55% examples, 529594 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:46,582 : INFO : EPOCH 3 - PROGRESS: at 21.96% examples, 532398 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:47,597 : INFO : EPOCH 3 - PROGRESS: at 24.35% examples, 533941 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:48,595 : INFO : EPOCH 3 - PROGRESS: at 26.89% examples, 535964 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:49,610 : INFO : EPOCH 3 - PROGRESS: at 28.30% examples, 516708 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:50,608 : INFO : EPOCH 3 - PROGRESS: at 30.61% examples, 518864 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:51,606 : INFO : EPOCH 3 - PROGRESS: at 32.66% examples, 515968 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:52,621 : INFO : EPOCH 3 - PROGRESS: at 34.77% examples, 513117 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:53,627 : INFO : EPOCH 3 - PROGRESS: at 36.79% examples, 509685 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:54,642 : INFO : EPOCH 3 - PROGRESS: at 38.83% examples, 506833 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:55,641 : INFO : EPOCH 3 - PROGRESS: at 41.01% examples, 505987 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:56,674 : INFO : EPOCH 3 - PROGRESS: at 43.14% examples, 504523 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:57,695 : INFO : EPOCH 3 - PROGRESS: at 45.34% examples, 503619 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:58,715 : INFO : EPOCH 3 - PROGRESS: at 47.33% examples, 500765 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 22:59:59,745 : INFO : EPOCH 3 - PROGRESS: at 48.22% examples, 486444 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:00,765 : INFO : EPOCH 3 - PROGRESS: at 50.28% examples, 485274 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:01,811 : INFO : EPOCH 3 - PROGRESS: at 51.89% examples, 479491 words/s, in_qsize 0, out_qsize 2\n",
      "2019-06-24 23:00:02,825 : INFO : EPOCH 3 - PROGRESS: at 53.54% examples, 475051 words/s, in_qsize 0, out_qsize 2\n",
      "2019-06-24 23:00:03,827 : INFO : EPOCH 3 - PROGRESS: at 55.81% examples, 476468 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:04,828 : INFO : EPOCH 3 - PROGRESS: at 58.04% examples, 477452 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:00:05,857 : INFO : EPOCH 3 - PROGRESS: at 60.08% examples, 476239 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:06,902 : INFO : EPOCH 3 - PROGRESS: at 62.44% examples, 477611 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:07,916 : INFO : EPOCH 3 - PROGRESS: at 64.90% examples, 480182 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:08,963 : INFO : EPOCH 3 - PROGRESS: at 66.33% examples, 473689 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:09,963 : INFO : EPOCH 3 - PROGRESS: at 68.81% examples, 477703 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:10,963 : INFO : EPOCH 3 - PROGRESS: at 71.31% examples, 479923 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:00:11,979 : INFO : EPOCH 3 - PROGRESS: at 74.26% examples, 482267 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:00:12,997 : INFO : EPOCH 3 - PROGRESS: at 77.13% examples, 484403 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:00:13,995 : INFO : EPOCH 3 - PROGRESS: at 80.00% examples, 486314 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:15,027 : INFO : EPOCH 3 - PROGRESS: at 82.96% examples, 488411 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:16,041 : INFO : EPOCH 3 - PROGRESS: at 84.01% examples, 480852 words/s, in_qsize 4, out_qsize 1\n",
      "2019-06-24 23:00:17,071 : INFO : EPOCH 3 - PROGRESS: at 87.21% examples, 484761 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:18,077 : INFO : EPOCH 3 - PROGRESS: at 90.20% examples, 487323 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:00:19,092 : INFO : EPOCH 3 - PROGRESS: at 93.11% examples, 489407 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:20,094 : INFO : EPOCH 3 - PROGRESS: at 95.95% examples, 491057 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:21,108 : INFO : EPOCH 3 - PROGRESS: at 98.02% examples, 490146 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:22,108 : INFO : EPOCH 3 - PROGRESS: at 99.05% examples, 484284 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:00:22,513 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-24 23:00:22,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-24 23:00:22,529 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-24 23:00:22,545 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-24 23:00:22,545 : INFO : EPOCH - 3 : training on 24232875 raw words (21808131 effective words) took 45.0s, 484291 effective words/s\n",
      "2019-06-24 23:00:23,554 : INFO : EPOCH 4 - PROGRESS: at 2.38% examples, 472003 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:24,563 : INFO : EPOCH 4 - PROGRESS: at 4.92% examples, 474973 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:25,568 : INFO : EPOCH 4 - PROGRESS: at 7.48% examples, 479669 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:26,576 : INFO : EPOCH 4 - PROGRESS: at 9.68% examples, 475282 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:27,595 : INFO : EPOCH 4 - PROGRESS: at 11.99% examples, 489892 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:28,608 : INFO : EPOCH 4 - PROGRESS: at 14.32% examples, 500554 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-24 23:00:29,606 : INFO : EPOCH 4 - PROGRESS: at 16.68% examples, 509013 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:31,049 : INFO : EPOCH 4 - PROGRESS: at 18.89% examples, 484345 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:32,063 : INFO : EPOCH 4 - PROGRESS: at 21.33% examples, 492710 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:33,080 : INFO : EPOCH 4 - PROGRESS: at 23.79% examples, 499238 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:34,094 : INFO : EPOCH 4 - PROGRESS: at 26.29% examples, 503967 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:35,093 : INFO : EPOCH 4 - PROGRESS: at 28.87% examples, 507792 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:36,091 : INFO : EPOCH 4 - PROGRESS: at 31.19% examples, 511894 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:37,113 : INFO : EPOCH 4 - PROGRESS: at 33.55% examples, 513343 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:38,127 : INFO : EPOCH 4 - PROGRESS: at 36.02% examples, 516008 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:39,115 : INFO : EPOCH 4 - PROGRESS: at 38.43% examples, 518154 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:40,145 : INFO : EPOCH 4 - PROGRESS: at 39.59% examples, 503292 words/s, in_qsize 4, out_qsize 1\n",
      "2019-06-24 23:00:41,151 : INFO : EPOCH 4 - PROGRESS: at 42.24% examples, 509135 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:00:42,150 : INFO : EPOCH 4 - PROGRESS: at 44.44% examples, 508360 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:43,179 : INFO : EPOCH 4 - PROGRESS: at 46.88% examples, 509833 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:44,185 : INFO : EPOCH 4 - PROGRESS: at 49.03% examples, 508607 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:45,183 : INFO : EPOCH 4 - PROGRESS: at 51.36% examples, 509278 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:46,197 : INFO : EPOCH 4 - PROGRESS: at 53.58% examples, 509001 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:47,200 : INFO : EPOCH 4 - PROGRESS: at 55.68% examples, 507649 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:48,371 : INFO : EPOCH 4 - PROGRESS: at 56.86% examples, 494852 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:49,385 : INFO : EPOCH 4 - PROGRESS: at 59.22% examples, 495985 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:50,400 : INFO : EPOCH 4 - PROGRESS: at 61.59% examples, 497171 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:51,411 : INFO : EPOCH 4 - PROGRESS: at 63.89% examples, 497918 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:52,410 : INFO : EPOCH 4 - PROGRESS: at 66.07% examples, 497161 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:53,424 : INFO : EPOCH 4 - PROGRESS: at 68.38% examples, 498778 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:54,426 : INFO : EPOCH 4 - PROGRESS: at 70.70% examples, 499906 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:55,440 : INFO : EPOCH 4 - PROGRESS: at 73.56% examples, 501456 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:56,777 : INFO : EPOCH 4 - PROGRESS: at 76.02% examples, 495656 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-24 23:00:57,791 : INFO : EPOCH 4 - PROGRESS: at 78.96% examples, 497808 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:58,805 : INFO : EPOCH 4 - PROGRESS: at 81.61% examples, 497770 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:00:59,804 : INFO : EPOCH 4 - PROGRESS: at 84.19% examples, 498276 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:00,818 : INFO : EPOCH 4 - PROGRESS: at 87.17% examples, 500679 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:01,832 : INFO : EPOCH 4 - PROGRESS: at 90.02% examples, 502358 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:02,855 : INFO : EPOCH 4 - PROGRESS: at 91.21% examples, 495466 words/s, in_qsize 1, out_qsize 1\n",
      "2019-06-24 23:01:03,869 : INFO : EPOCH 4 - PROGRESS: at 93.94% examples, 496471 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:04,874 : INFO : EPOCH 4 - PROGRESS: at 96.33% examples, 495898 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:05,877 : INFO : EPOCH 4 - PROGRESS: at 98.77% examples, 496859 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:06,361 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-24 23:01:06,361 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-24 23:01:06,361 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-24 23:01:06,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-24 23:01:06,392 : INFO : EPOCH - 4 : training on 24232875 raw words (21806154 effective words) took 43.8s, 497449 effective words/s\n",
      "2019-06-24 23:01:07,391 : INFO : EPOCH 5 - PROGRESS: at 2.71% examples, 528975 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:08,396 : INFO : EPOCH 5 - PROGRESS: at 5.62% examples, 543283 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:09,445 : INFO : EPOCH 5 - PROGRESS: at 7.20% examples, 459178 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:10,429 : INFO : EPOCH 5 - PROGRESS: at 9.99% examples, 490176 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:11,458 : INFO : EPOCH 5 - PROGRESS: at 12.36% examples, 506161 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:12,459 : INFO : EPOCH 5 - PROGRESS: at 14.59% examples, 510634 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:13,457 : INFO : EPOCH 5 - PROGRESS: at 16.98% examples, 518929 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:01:14,471 : INFO : EPOCH 5 - PROGRESS: at 19.32% examples, 522112 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:15,470 : INFO : EPOCH 5 - PROGRESS: at 21.69% examples, 524961 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:16,485 : INFO : EPOCH 5 - PROGRESS: at 23.88% examples, 522796 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:17,483 : INFO : EPOCH 5 - PROGRESS: at 26.29% examples, 524536 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:18,708 : INFO : EPOCH 5 - PROGRESS: at 28.17% examples, 504773 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:01:19,723 : INFO : EPOCH 5 - PROGRESS: at 30.69% examples, 510722 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:20,738 : INFO : EPOCH 5 - PROGRESS: at 33.15% examples, 514418 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:21,752 : INFO : EPOCH 5 - PROGRESS: at 35.37% examples, 513313 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:01:22,767 : INFO : EPOCH 5 - PROGRESS: at 37.79% examples, 515286 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:23,774 : INFO : EPOCH 5 - PROGRESS: at 40.14% examples, 516634 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:24,788 : INFO : EPOCH 5 - PROGRESS: at 42.57% examples, 518546 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:25,802 : INFO : EPOCH 5 - PROGRESS: at 44.89% examples, 518470 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:26,808 : INFO : EPOCH 5 - PROGRESS: at 47.33% examples, 519966 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:27,807 : INFO : EPOCH 5 - PROGRESS: at 48.55% examples, 508459 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:01:28,806 : INFO : EPOCH 5 - PROGRESS: at 51.12% examples, 511678 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:29,821 : INFO : EPOCH 5 - PROGRESS: at 53.54% examples, 513222 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:30,838 : INFO : EPOCH 5 - PROGRESS: at 55.97% examples, 514412 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:31,859 : INFO : EPOCH 5 - PROGRESS: at 58.45% examples, 515811 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:32,844 : INFO : EPOCH 5 - PROGRESS: at 60.86% examples, 516840 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:33,873 : INFO : EPOCH 5 - PROGRESS: at 63.32% examples, 518245 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:34,877 : INFO : EPOCH 5 - PROGRESS: at 65.80% examples, 519509 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:35,892 : INFO : EPOCH 5 - PROGRESS: at 67.17% examples, 511819 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:36,897 : INFO : EPOCH 5 - PROGRESS: at 69.53% examples, 514007 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:37,919 : INFO : EPOCH 5 - PROGRESS: at 72.21% examples, 514987 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:38,934 : INFO : EPOCH 5 - PROGRESS: at 75.20% examples, 516425 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:39,964 : INFO : EPOCH 5 - PROGRESS: at 78.06% examples, 517521 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-24 23:01:40,969 : INFO : EPOCH 5 - PROGRESS: at 80.92% examples, 517909 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-24 23:01:42,092 : INFO : EPOCH 5 - PROGRESS: at 82.79% examples, 512143 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-24 23:01:43,105 : INFO : EPOCH 5 - PROGRESS: at 85.95% examples, 515313 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:44,104 : INFO : EPOCH 5 - PROGRESS: at 88.87% examples, 517161 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:45,103 : INFO : EPOCH 5 - PROGRESS: at 91.79% examples, 518819 words/s, in_qsize 1, out_qsize 0\n",
      "2019-06-24 23:01:46,140 : INFO : EPOCH 5 - PROGRESS: at 94.60% examples, 519278 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-24 23:01:47,155 : INFO : EPOCH 5 - PROGRESS: at 96.77% examples, 517359 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:48,169 : INFO : EPOCH 5 - PROGRESS: at 97.68% examples, 509624 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:49,174 : INFO : EPOCH 5 - PROGRESS: at 99.87% examples, 509039 words/s, in_qsize 0, out_qsize 0\n",
      "2019-06-24 23:01:49,205 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-06-24 23:01:49,220 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-24 23:01:49,220 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-24 23:01:49,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-24 23:01:49,236 : INFO : EPOCH - 5 : training on 24232875 raw words (21808000 effective words) took 42.8s, 509004 effective words/s\n",
      "2019-06-24 23:01:49,236 : INFO : training on a 121164375 raw words (109037293 effective words) took 216.7s, 503210 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(109037293, 121164375)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.train(\n",
    "    sents,\n",
    "    total_examples=w2v.corpus_count,\n",
    "    epochs=w2v.epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('referoiden', 0.518416166305542),\n",
       " ('pÃ¤tevÃ¤sti', 0.5164487361907959),\n",
       " ('deus', 0.5112777948379517),\n",
       " ('sapiens', 0.4446752667427063),\n",
       " ('uskovainen', 0.4147804379463196),\n",
       " ('transagendansa', 0.41277870535850525),\n",
       " ('Allahiin', 0.4052746295928955),\n",
       " ('joillain', 0.37194502353668213),\n",
       " ('otetuista', 0.3689946234226227),\n",
       " ('Hararin', 0.3660024404525757)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('homo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
